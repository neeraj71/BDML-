---
title: "Topic You are Writing About"
author: John Appleseed <ja@example.com>
---
# Introduction
Present an overview of the problem and the approaches.


# Motivation
What is the problem that the papers are looking at, and why are they looking at
this? 
This is a bit harder for the two introduction lectures, since they try to
overview the area.

# Approaches
Talk a bit about the approaches the papers discussed, and what you found from
your research.

A GFS cluster has multiples clients, one master and multiple chunkservers. Chunkservers store the actual data as Linux files. Files are divided into fixed size (64 Mb) chunks. Chunks are labelled by 64-bit unique global ids (chunk handles). A chunk is by default replicated over 3 chunkservers to attain reliabality. A user can also specify the number of replicas. Master keeps track of which chunks belongs to which files and helps the client to locate the chunks. Master contains a table with keys as file name and values as list of chunk handles. For example, a 1 GB file would be divided into 17 chunks (need to store ids/handle of these 17 chunks). It also contains a table with chunk handles as keys and list of chunkservers holding the corresponding data as values. Since a chunk is replicated over many chunkservers, Master needs to store the mapping from chunk handle to all those chunkservers. This table helps to locate all the replicas of a given chunk handle. The Master contains a version number of each chunk. It also contains info whether a chunk is primary and the lease expiration time. 

Master contains all the metadata in RAM for fast access. However to prevent the data loss on reboot, Master saves the metadata to hard drive (non-volatile memory) except the version number, lease experiment time and table from chunk handle to chunkservers. Because a chunkserver might be dead when master rebooted. Hence, master would not want to send the location of dead chunkservers to clients. Every time master reboots, it would check the health of chunkserver by sending hearbeat messages and reconstructs the mapping. Apart from saving the logs on the disk, Master also create checkpoints in a regular interval of time for the fast reloading afer a crash.


## Read

* Application specifies the file name and offset.
* Client computes the chunk index (divide offset by 64). Client sends read request to Master containing filename and chunk index.
* Master reverts back with chunk handles and location of replicas.
* Client caches this to reduce the interactions with Master (don't want to overload the Master).
* Client talks to one of the closest replicas. Client tells the chunk handle and the byte range to read to chunkserver.
* Chunkserver reads the desired bytes and returns the data to clients.

## Record Appends

* Application originates record append request.
* Client aks for location of Primary (lease holder) chunkserver and all other replicas (Secondary) to Master. If there exists a chunkserver with lease or Primary chunkserver  then the master returns the locations of Primary and Secondary chunkservers. Otherwise the Master finds out set of chunserver that have most up-to-date replicas.
As we know, Master holds the version number to distinguish between the stale copies of the chunk vs up-to-date. A replicas is said to be most up-to-date if its version number is equal to the version number that Master knows. Master picks one of the most up-to-date chunkservers as the Primary chunkserver and other most up-to-date chunkservers as Secondary. Master grants a lease for 60sec to Primary chunkserver. Lease mechanism is used for consistent mutation across replicas. This is ensured by forcing a single Primary for a chunk. Master sends heartbeat messages to Primary but if it doesn't receive any reply from Primary it won't assign a new Primary until the lease expires. If there was no lease mechanism, and Master doesn't receive reply from Primary due to network fault then the Master would have assigned a new primary resulting into two primary chunkservers writing over the same chunk (* "Split Brain " *) and the system wouldn't be consistent. 
* Client sends a copy of the data to be appended to the primary and secondary chunkservers. Primary and secondary chunkservers write that data to temporary location (not appended yet). Once the replicas responds that they have received the data. The client sends append request to primary. (Paper suggests that in order to maximize bandwidth and throughput, the client would send data to only one of the replica, then replicas send the data in a chain to all other replicas)
* Primary receives requests concurrently from many clients. It picks some order and executes the requests one at a time. Primary decides offset and writes record at the end of the chunk and asks secondary to write at the same offset in the same order.
* However Sencondary may or may not be able to append the record. If Secondary chunkservers were successful in appending the record, they reply "yes" to primary and primary says success to the client. If even one of secondary chunkserver fails to append the record, the primary would report failure to the client. So, if client receives success it implies that the record is appended at the same offset in all replicas. If client receives failure then the atleast in one of the replicas the record wasn't appended. In such cases, the primary would try to refresh the lease and start the process agains. However, if the primary is unable to do so, the client would make a fresh request to Master. The client would keep making requests until the record is appended. This ensures that a record would be appended atleast once in all the replicas.

# Trade-Offs
Compare the approaches, discuss when they might be appropriate. For example,
some techniques might only make sense with a lot of data, or in the absence of
multiple tenants, etc.

## Relaxed Consistency
GFS has a very good throuhput but at the cost of some relaxation in consistency during writes/record appends. Suppose that client A made an append request to the primary chunkserver (with 2 secondary chunkservers). The client got a success reply from the primary. This means that record was appended in all three replicas. Now, the client B makes an append request and got a failure reply from the primary because one of the secondary chunkserver failed to append the record. However primary and the other secondary successfully appended the record. Client B would continue to retry until it gets success. In between client C makes an append request to primary and gets success reply. Now  client B again makes an append request to primary and this time gets a success reply. This results in the duplication of the record of client B at the primary and one of the secondary chunkserver. Moreover the order in which records got appended is not same in the two secondary chunkservers. Also, if a client D makes an append request and it gets failed and the client dies then atleast one of the replica would be missing the record forever. Howerver, these inconsistencies occur very rarely and doesn't matter much in application which uses GFS, for eg. in search results if we miss out a single record among thousands.

## Chunk Size



## Replica Location


# Open Questions and Future Work
How are the current trends affecting the area, what are some open questions
about the problem, etc.
