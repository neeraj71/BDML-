---
title: "The Google File System"
author: Neeraj Yadav <ny736@nyu.edu>
---
# Introduction
Present an overview of the problem and the approaches.
The paper deals with providing a distributed file system which is scalable, reliable, available, fault tolerant and efficient for sequential read and writes. GFS provides concurrent access to hundreds of clients to files using a single master and thousands of chunkservers which stores files.


# Motivation
What is the problem that the papers are looking at, and why are they looking at
this? 
This is a bit harder for the two introduction lectures, since they try to
overview the area.
As the data grew there was a need to split the data across many machines for efficient processing. Google developed a distributed File system called as GFS that can handle the large data and files. GFS was developed to work reliably on commodity hardwares (cheap machines) where component failure is very common. It was designed to store the big files from 100Mbs to multiple Gbs. Though it can work on small files but it was optimized for big files. Because Google needed an infrasturcture for the big files and GFS was exclusively developed for the internal use. It was developed for big sequential reads and writes (appending at the end of file). Because Google observed that their applications which would run on top of GFS would be reading the data sequentially and also there would be negligible random writes and overwriting. The focus was on high sustained bandwidth (throughput) than low latency. Google observed that they don't need a strong consistent system and it is okay to miss one or two search results among thousands. Hence the system relaxed the consistency. 


# Approaches
Talk a bit about the approaches the papers discussed, and what you found from
your research.

A GFS cluster has multiples clients, one master and multiple chunkservers. Chunkservers store the actual data as Linux files. Files are divided into fixed size (64 Mb) chunks. Chunks are labelled by 64-bit unique global ids (chunk handles). A chunk is by default replicated over 3 chunkservers to attain reliabality. A user can also specify the number of replicas. Master keeps track of which chunks belongs to which files and helps the client to locate the chunks. Master contains a table with keys as file name and values as list of chunk handles. For example, a 1 GB file would be divided into 17 chunks (need to store ids/handle of these 17 chunks). It also contains a table with chunk handles as keys and list of chunkservers holding the corresponding data as values. Since a chunk is replicated over many chunkservers, Master needs to store the mapping from chunk handle to all those chunkservers. This table helps to locate all the replicas of a given chunk handle. The Master contains a version number of each chunk. It also contains info whether a chunk is primary and the lease expiration time. 

Master contains all the metadata in RAM for fast access. However to prevent the data loss on reboot, Master saves the metadata to hard drive (non-volatile memory) except the version number, lease experiment time and table from chunk handle to chunkservers. Because a chunkserver might be dead when master rebooted. Hence, master would not want to send the location of dead chunkservers to clients. Every time master reboots, it would check the health of chunkserver by sending hearbeat messages and reconstructs the mapping. Apart from saving the logs on the disk, Master also create checkpoints in a regular interval of time for the fast reloading afer a crash.


## Read

* Application specifies the file name and offset.
* Client computes the chunk index (divide offset by 64). Client sends read request to Master containing filename and chunk index.
* Master reverts back with chunk handles and location of replicas.
* Client caches (only metadata) this to reduce the interactions with Master (don't want to overload the Master).
* Client talks to one of the closest replicas. Client tells the chunk handle and the byte range to read to chunkserver.
* Chunkserver reads the desired bytes and returns the data to clients.

## Record Appends

* Application originates record append request.
* Client aks for location of Primary (lease holder) chunkserver and all other replicas (Secondary) to Master. If there exists a chunkserver with lease or Primary chunkserver  then the master returns the locations of Primary and Secondary chunkservers. Otherwise the Master finds out set of chunserver that have most up-to-date replicas.
As we know, Master holds the version number to distinguish between the stale copies of the chunk vs up-to-date. A replicas is said to be most up-to-date if its version number is equal to the version number that Master knows. Master picks one of the most up-to-date chunkservers as the Primary chunkserver and other most up-to-date chunkservers as Secondary. Master grants a lease for 60sec to Primary chunkserver. Lease mechanism is used for consistent mutation across replicas. This is ensured by forcing a single Primary for a chunk. Master sends heartbeat messages to Primary but if it doesn't receive any reply from Primary it won't assign a new Primary until the lease expires. If there was no lease mechanism, and Master doesn't receive reply from Primary due to network fault then the Master would have assigned a new primary resulting into two primary chunkservers writing over the same chunk (*Split Brain*) and the system wouldn't be consistent. 
* Client sends a copy of the data to be appended to the primary and secondary chunkservers. Primary and secondary chunkservers write that data to temporary location (not appended yet). Once the replicas responds that they have received the data. The client sends append request to primary. (Paper suggests that in order to maximize bandwidth and throughput, the client would send data to only one of the replica, then replicas send the data in a chain to all other replicas)
* Primary receives requests concurrently from many clients. It picks some order and executes the requests one at a time. Primary decides offset and writes record at the end of the chunk and asks secondary to write at the same offset in the same order.
* However Sencondary may or may not be able to append the record. If Secondary chunkservers were successful in appending the record, they reply "yes" to primary and primary says success to the client. If even one of secondary chunkserver fails to append the record, the primary would report failure to the client. So, if client receives success it implies that the record is appended at the same offset in all replicas. If client receives failure then the atleast in one of the replicas the record wasn't appended. In such cases, the primary would try to refresh the lease and start the process agains. However, if the primary is unable to do so, the client would make a fresh request to Master. The client would keep making requests until the record is appended. This ensures that a record would be appended atleast once in all the replicas.

# Trade-Offs
Compare the approaches, discuss when they might be appropriate. For example,
some techniques might only make sense with a lot of data, or in the absence of
multiple tenants, etc.

## Relaxed Consistency
GFS has a very good throuhput but at the cost of some relaxation in consistency during writes/record appends. Suppose that client A made an append request to the primary chunkserver (with 2 secondary chunkservers). The client got a success reply from the primary. This means that record was appended in all three replicas. Now, the client B makes an append request and got a failure reply from the primary because one of the secondary chunkserver failed to append the record. However primary and the other secondary successfully appended the record. Client B would continue to retry until it gets success. In between client C makes an append request to primary and gets success reply. Now  client B again makes an append request to primary and this time gets a success reply. This results in the duplication of the record of client B at the primary and one of the secondary chunkserver. Moreover the order in which records got appended is not same in the two secondary chunkservers. Also, if a client D makes an append request and it gets failed and the client dies then atleast one of the replica would be missing the record forever. However, these inconsistencies occur very rarely and doesn't matter much in application which uses GFS, for eg. in search results if we miss out a single record among thousands.

## Chunk Size
GFS used a chunk size of 64Mb which is quite large. Larger chunk size reduced the client master interaction because reads and writes on the same chunk require only one request from client to master and after that client can used cached locations. This is supported by the fact that most of read/write operation are sequential. Also, large chunk size implies fewer chunks and less master's metadata in RAM. It also reduces the network overhead. The disadvantage of large chunk size is that it can lead to fragmentation if there are large number of small files. If file is small then it would get fitted in one chunk and if multiple clients are accessing that chunk then it would become hotspot.

## Replica Location
In GFS the replicas are spread across the racks. This give more reliability if an entire rack is damaged. Since we choose one of the replicas during read, this would give us the average bandwidth of multiple racks while reading. The downside is that during write operations the data has to flow through multiple racks.  

## Client Caching: Throughput vs Consistency
Client caching improves throughput and perfromance but there are consistency issues. As clients caches the chunk locations, it's possible that they may read from stale replica before the information is updated. This results to inconsistency but fortunately it is short lived. Because the cached metadata expires after a fixed time or if the file is reopened again.

## Garbage  Collection

GFS doesn't reclaim the space immediately during deleting a file. It first renames that files and removes them only if the file was renamed x (default value 3) or more days before. The advantage of this process is that it is done when master is relaively free and it is simple and reliable. The disadvantage is that we won't be able to access the storage immediately. 

# Open Questions and Future Work
How are the current trends affecting the area, what are some open questions
about the problem, etc.

GFS proved to be very successful for Google as many applications like BigTable, MapReduce run over it. However as number of files increases, the metadata also increases making it challenging for master to store the metadata in RAM. This is an open problem to store the metadata for large number of files. Other areas that need to look after are to manage the load on single master from thousands of clients and automatic recovery of master (in case of failure) without human intervention. In future, a two-phase mechanism can be tried out to make the system consistent while appending the records. For this, the primary chunkserver first needs to ask to all the secondary chunkservers whether they can append the request and if they reply "yes" then only it orders them to append the record. A duplicate detection mechanism can be used to remove the duplicate appended records in the replicas.

